---
title: "Appalachian Gauges"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Site selection and data cleaning:
```{r, echo=FALSE}
library(tidyverse)
library(ggforce)
library(dataRetrieval)
library(sf)
library(tmap)
library(spData)
library(repr)
library(zoo)
library(lubridate)
library(moments)
library(broom)
library(AICcmodavg)
library(raster)
library(rgdal)
library(mapview)
library(ranger)

library(tidymodels)

library(Hmisc)
library(patchwork)
library(ggpmisc)
library(modelr)

tmap_mode("plot")

theme_set(theme_classic())
```


## Read in shapefile for Appalachian physiographic region

Excluding St. Lawrence Valley, New England Uplands, and Seaboard
Lowlands sections.

## Read in shapefile for gages

Gages from CAMELS dataset, GAGESII shapefile joined to station by Gage ID

```{r}
AppRegions <- st_read("Data/Shapefiles/AppalachianRegions.shp")

AppGages <- read_csv("Data/SAgages.csv")

AppGagesshp <- st_read("Data/SAgages.shp") 

ProvinceMap <- tm_shape(AppRegions)+
  tm_polygons(col = "PROVINCE", palette = "Spectral")+
  tm_layout(legend.outside = TRUE)+
tm_shape(AppGagesshp)+
  tm_dots()+
tm_shape(us_states)+
  tm_borders()

ProvinceMap
head(AppGages)

mapview(AppGagesshp)
```
## Join watershed attributes from CAMELS dataset:

 - Can add more watershed characteristics here.
```{r}
WSfactors <- full_join(read_delim("CAMELS Data/camels_clim.txt"), read_delim("CAMELS Data/camels_geol.txt"), by = "gauge_id") %>%
  full_join(read_delim("CAMELS Data/camels_soil.txt"), by = "gauge_id") %>%
  inner_join(AppGages, by = "gauge_id")

write_csv(WSfactors, "CAMELSapps_attr.csv")
```

## Cleaning data for random forest
```{r}
RFpredictors <- read_delim("CAMELS Data/camels_hydro.txt")|>
  filter(gauge_id %in% AppGages$gauge_id) |>
  na.omit()

#All other CAMELS data
params <- full_join(read_delim("CAMELS Data/camels_clim.txt"),
                                     read_delim("CAMELS Data/camels_geol.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_soil.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_topo.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_vege.txt"), by = "gauge_id") |> 
  full_join(read_delim("CAMELS Data/camels_name.txt"), by = "gauge_id")

head(params)

#need to remove NA's -- could either remove the gauge or the entire variable
forRF <- params |>
  filter(gauge_id %in% AppGages$gauge_id) |>
  dplyr::select(-gauge_id, -gauge_name, -area_gages2, -area_geospa_fabric, -geol_2nd_class) |>
  na.omit()

#Match observation length to hypergrid length (model tuning)
forRF <- forRF %>%
  slice_tail(n = 80)

RFpredictors <- RFpredictors %>%
  slice_tail(n=80)

```
## Playing around with tidymodels
```{r}
# Aggregate BFI to predictors data
forRF_BFI <- left_join(AppGages, dplyr::select(RFpredictors, gauge_id, baseflow_index), by = "gauge_id") |> 
  dplyr::select(-baseflow_index.y) |> 
  rename("baseflow_index" = "baseflow_index.x")


```



### Prep for Model:
 - hyper_grid: possible combinations for model
 - train model, use BFI as predictor variable
```{r}
# hyperparameter grid search
hyper_grid <- expand.grid(
  #mtry       = seq(20, 30, by = 2), #mtry should be square of available params (35)
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
nrow(hyper_grid)
## [1] 80

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = RFpredictors$baseflow_index ~ ., #BFI is what you're trying to predict 
    data            = forRF, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

#print RMSE
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE)
```
# Potentially use tideymodels
```{r}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger <- ranger(
    formula         = RFpredictors$baseflow_index ~ ., 
    data            = forRF, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#for perKGC plot
BFI_importancesAll <- optimal_ranger$variable.importance %>% 
      as_tibble() %>% 
      bind_cols(names(optimal_ranger$variable.importance)) %>%
      rename(importance = value, param = '...2') %>%
      mutate(measure = "BFI")

#filter to see top variables
BFI_tTen <- BFI_importancesAll %>%
  arrange(desc(importance)) 

BFI_tTen <- BFI_tTen[1:10,]

BFI_tTen %>%
  ggplot(aes(x = param, y = importance)) +
  geom_bar(stat="identity")

BFI_com <- intersect(colnames(forRF), BFI_tTen$param)

BFI_var <- forRF |>
  dplyr::select(BFI_com) |>
  dplyr::select(-geol_1st_class)

```


```{r}
cor_matrix <- cor(BFI_var)

print(cor_matrix)

# Check for missing and infinite values in the data
any(is.na(BFI_var))

forMR <- cbind(BFI_var, RFpredictors$baseflow_index)

# Fit a stepwise regression model with the selected predictors
BFI_step_model <- step(lm(forMR$`RFpredictors$baseflow_index` ~ ., data = forMR), direction = "both")

# Print the model summary
summary(BFI_step_model)

BFIpred <- forMR %>%
  add_predictions(BFI_step_model) |>
  rename("BFI_actual" = "RFpredictors$baseflow_index")

BFI <- 
  BFIpred %>% drop_na() %>%
  ggplot(aes(x = BFI_actual, y = pred)) +
  geom_point() +
  stat_poly_line(method=lm) +
  stat_poly_eq() +
  xlab("Actual BFI") +
  ylab("Predicted BFI") +
  theme_classic()

BFI
```

# Predicting for q5
```{r}
# hyperparameter grid search
hyper_grid <- expand.grid(
  #mtry       = seq(20, 30, by = 2), #mtry should be square of available params (35)
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
nrow(hyper_grid)
## [1] 80

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = RFpredictors$q5 ~ ., #BFI is what you're trying to predict 
    data            = forRF, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

#print RMSE
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE)

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger <- ranger(
    formula         = RFpredictors$q5 ~ ., 
    data            = forRF, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#for perKGC plot
Q5_importancesAll <- optimal_ranger$variable.importance %>% 
      as_tibble() %>% 
      bind_cols(names(optimal_ranger$variable.importance)) %>%
      rename(importance = value, param = '...2') %>%
      mutate(measure = "Q5")

#filter to see top variables
q5_tTen <- Q5_importancesAll %>%
  arrange(desc(importance)) 

q5_tTen <- q5_tTen[1:10,]

q5_tTen %>%
  ggplot(aes(x = param, y = importance)) +
  geom_bar(stat="identity")

q5_com <- intersect(colnames(forRF), q5_tTen$param)

q5_var <- forRF |>
  dplyr::select(q5_com) 

cor_matrix <- cor(q5_var)

print(cor_matrix)

# Check for missing and infinite values in the data
any(is.na(q5_var))

forMR <- cbind(q5_var, RFpredictors$q5)

# Fit a stepwise regression model with the selected predictors
q5_step_model <- step(lm(forMR$`RFpredictors$q5` ~ ., data = forMR), direction = "both")

# Print the model summary
summary(q5_step_model)

q5pred <- forMR %>%
  add_predictions(q5_step_model) |>
  rename("q5_actual" = "RFpredictors$q5")

Q5 <-  q5pred %>% drop_na() %>%
  ggplot(aes(x = q5_actual, y = pred)) +
  geom_point() +
  stat_poly_line(method=lm) +
  stat_poly_eq() +
  xlab("Actual Q5") +
  ylab("Predicted Q5") +
  theme_classic()

Q5
```

## Predicting for Q95
```{r}
# hyperparameter grid search
hyper_grid <- expand.grid(
  #mtry       = seq(20, 30, by = 2), #mtry should be square of available params (35)
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

# total number of combinations
nrow(hyper_grid)
## [1] 80

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = RFpredictors$q95 ~ ., #BFI is what you're trying to predict 
    data            = forRF, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

#print RMSE
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE)

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger <- ranger(
    formula         = RFpredictors$q95 ~ ., 
    data            = forRF, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#for perKGC plot
Q95_importancesAll <- optimal_ranger$variable.importance %>% 
      as_tibble() %>% 
      bind_cols(names(optimal_ranger$variable.importance)) %>%
      rename(importance = value, param = '...2') %>%
      mutate(measure = "Q95")

#filter to see top variables
q95_tTen <- Q95_importancesAll %>%
  arrange(desc(importance)) 

q95_tTen <- q95_tTen[1:10,]

q95_tTen %>%
  ggplot(aes(x = param, y = importance)) +
  geom_bar(stat="identity")

q95_com <- intersect(colnames(forRF), q95_tTen$param)

q95_var <- forRF |>
  dplyr::select(q95_com) 

cor_matrix <- cor(q95_var)

print(cor_matrix)

# Check for missing and infinite values in the data
any(is.na(q95_var))

forMR <- cbind(q95_var, RFpredictors$q95)

# Fit a stepwise regression model with the selected predictors
q95_step_model <- step(lm(forMR$`RFpredictors$q95` ~ ., data = forMR), direction = "both")

# Print the model summary
summary(q95_step_model)

q95pred <- forMR %>%
  add_predictions(q95_step_model) |>
  rename("q95_actual" = "RFpredictors$q95")

Q95 <-  q95pred %>% drop_na() %>%
  ggplot(aes(x = q95_actual, y = pred)) +
  geom_point() +
  stat_poly_line(method=lm) +
  stat_poly_eq() +
  xlab("Actual Q95") +
  ylab("Predicted Q95") +
  theme_classic()

Q95
```

## Some data manipulation for accessing the daily streamflow records for gauge id's
```{r}
library(purrr)
library(fs)

QdatBaseflow <- read_delim("CAMELS Data/camels_hydro.txt")|>
  filter(gauge_id %in% AppGages$gauge_id) |>
  na.omit()

# Get gauge IDs
gauge_ids <- AppGages$gauge_id

dir <- "C:/Users/lfink/Desktop/camels API scripts/basin_dataset_public_v1p2/usgs_streamflow"

# Get a list of all text files in the directory and its subdirectories
all_files <- list.files(path = dir, pattern = "\\.txt$", full.names = TRUE, recursive = TRUE)

column_names <- c("gauge_id", "year", "month", "day", "q", "QCflag")

# Initialize an empty list to store the data frames
data_list <- list()

# Loop through the gauge IDs
for (id in gauge_ids) {
  # Create the file name pattern
  pattern <- paste0(id, "_streamflow_qc.txt$")
  
  # Find the file that matches the current gauge ID
  file <- grep(pattern, all_files, value = TRUE)
  
  # Check if the file exists
  if (length(file) > 0) {
    # Read the file and store it in the list
    data_list[[id]] <- read.table(file, header = FALSE, col.names = column_names, sep = "")
  }
}

# Bind all the data frames in the list
AppsDailyQ <- bind_rows(data_list)

#Check for gaps in data
unique(AppsDailyQ$QCflag)

#Filter out days where flow info is missing (QCflag = M)
AppsDailyQ <- AppsDailyQ |> 
  filter(QCflag != "M") |>
  #filter(QCflag != "A:e") |> 
  mutate(date = dmy(paste(day, month, year))) |> 
  dplyr:: select(-year, -month, -day)
  
AppsDailyQ$gauge_id <- as.character(AppsDailyQ$gauge_id) 
AppsDailyQ$gauge_id <- paste0("0", AppsDailyQ$gauge_id)

```

 ## Calculating RBI (flashiness):
 
 Baseflow separation:
  - need to acquire CAMELS timeseries data
```{r}

source("BaseflowSeparation.R")

#need to calculate flow in mm/day
QdatDV <- left_join(AppsDailyQ, AppGages, by="gauge_id") 

QdatDV <- QdatDV |> 
  mutate(Qmm_day = 2.447 * q / DRAIN_SQKM)

# Might want to write out this big CSV here!
#Input: Vector with baseflow
# Quick flow: total flow - baseflow
QdatDV$baseflow <- NA

for (x in gauge_ids) {
  QdatDV$baseflow[QdatDV$gauge_id == x] <- 
    BaseflowSeparation(QdatDV$Qmm_day[QdatDV$gauge_id == x])$bt
  
}

QdatDV |> 
  filter(gauge_id == gauge_ids[1]) |> 
  ggplot(aes(x = date, y = Qmm_day)) +
  geom_line() +
  geom_line(aes(y=baseflow), color = "blue")

#sum total flow, baseflow for each gage each year. BFI calculation
BFyearlysum <- QdatBaseflow %>% mutate(Year = year(date)) %>%
  group_by(year, gauge_id) %>%
  summarize(BFyear = sum(bt),
            Qyear = sum(Flow),
            BFI = BFyear / Qyear)

#join to attributes
BFyearlysum <- left_join(BFyearlysum, AppGagesSlim, by = c("site_no" = "STAID"))

#average annual BFI
BFI_means <- BFyearlysum %>% group_by(site_no) %>%
  summarize(BFI_MeanAnnual = mean(BFI))

#join to attributes
BFI_means <- inner_join(BFI_means, AppGagesSlim, by = c("site_no" = "STAID"))
```
  
  