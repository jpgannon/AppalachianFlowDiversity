---
title: "Appalachian Gauges"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries :
```{r, echo=FALSE}
#| warning: false

library(tidyverse)
library(ggforce)
library(sf)
library(tmap)
library(spData)
library(lubridate)
library(moments)
library(raster)
library(rgdal)
library(mapview)
library(ranger)
library(ggpmisc)
library(modelr)
library(viridis)
library(RColorBrewer)
library(patchwork)
library(corrplot)
library(datawizard)
library(tidymodels)
library(tigris)
library(viridisLite)
library(tidyr)
library(dplyr)

library(GGally)

tmap_mode("plot")

theme_set(theme_classic())
```

## Read in shapefile for Appalachian physiographic region

Excluding St. Lawrence Valley, New England Uplands, and Seaboard
Lowlands sections.

## Read in shapefile for gages

Gages from CAMELS dataset, GAGESII shapefile joined to station by Gage ID

```{r}
AppRegions <- st_read("Data/Shapefiles/AppalachianRegions.shp")

AppGages <- read_csv("CAMELSapps_attr.csv")

AppGagesshp <- st_read("Data/Shapefiles/AppGages_signatures.shp")

signatures <- read_delim("CAMELS Data/camels_hydro_all.csv")|>
  filter(gauge_id %in% AppGages$gauge_id) |> 
  na.omit()

AppGagesshp <- AppGagesshp %>%
  filter(gauge_id != "03281100")

ProvinceMap <- tm_shape(AppRegions)+
  tm_polygons(col = "PROVINCE", palette = "Spectral")+
  tm_layout(legend.outside = TRUE)+
tm_shape(AppGagesshp)+
  tm_dots()+
tm_shape(us_states)+
  tm_borders()

ProvinceMap

```

## Plots:
 - Study Area Map(s)
 - Signature maps
```{r, fig.width=12, fig.height=6}
ProvinceMap <- tm_shape(AppRegions)+
  tm_polygons(col = "PROVINCE", palette = "BuGn")+
  tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1)+
tm_shape(AppGagesshp)+
  tm_dots(size = 0.1)+
tm_shape(us_states)+
  tm_borders()

ProvinceMap

bfi <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "baseflow_i", palette = "-viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("Baseflow Index",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 

bfi

lflo <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "q5", palette = "-viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("Low Flow (5%)",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 

lflo

hflo <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "q95", palette = "viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("High Flow (95%)",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 
hflo

runr <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "runoff_rat", palette = "-viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("Runoff Ratio",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 

runr

qmd <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "q_mean", palette = "-viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("Mean Daily Discharge",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 

qmd

rbi <- tm_shape(AppRegions) +
  tm_fill("gray90")+
  tm_shape(us_states)+
  tm_borders() +
  tm_shape(AppGagesshp) +
  tm_dots(col = "RBI", palette = "-viridis", size = 0.3, border.col = "gray38", shape = 21) +
  tm_layout("RBI",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.position = c("right","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1) 

rbi

tmap_arrange(qmd, lflo, hflo, runr, bfi, rbi, ncol = 3)

#tmap_save(Maps, "RFMaps.png")
```
 
## Read in and clean data for Random Forest.

params: watershed characteristic data from CAMELS
standard_p: standardized parameters, continous variables only
signatures: signatures to predict for in RF

```{r}
params <- full_join(read_delim("CAMELS Data/camels_clim.txt"),
                    read_delim("CAMELS Data/camels_geol.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_soil.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_topo.txt"), by = "gauge_id") |>
  full_join(read_delim("CAMELS Data/camels_vege.txt"), by = "gauge_id") |> 
  full_join(read_delim("CAMELS Data/camels_name.txt"), by = "gauge_id")

standard_p <- params |>
  filter(gauge_id %in% AppGages$gauge_id) |>
  dplyr::select(-gauge_id, -gauge_name, -area_gages2, -area_geospa_fabric, -geol_2nd_class, 
                -huc_02, gauge_name, -high_prec_timing, -low_prec_timing, - dom_land_cover, -gauge_name, -geol_1st_class, -gauge_lat, -gauge_lon) |>
  mutate(across(where(is.character), as.factor)) |> 
  na.omit()

standard_p <- standard_p |> 
  standardize()

signatures <- read_delim("CAMELS Data/camels_hydro_all.csv")|>
  filter(gauge_id %in% AppGages$gauge_id) |>
  na.omit()

signatures <- signatures |> 
  dplyr::select(q_mean, baseflow_index, q5, q95, RBI, Qmean_mm_yr, runoff_ratio)
```

# Correlation matrix and PCA

```{r, fig.width=12, fig.height=8}
library(factoextra)
library(FactoMineR)

cor_matrix <- cor(standard_p)

corrplot(cor_matrix)

GGally::ggcorr(standard_p,
              method = c("everything", "pearson"),
              name = expression(rho),
              angle = -45,
              label = TRUE,
              label_alpha = TRUE)

# PCA
pca <- prcomp(cor_matrix, 
              center = TRUE,
              scale = TRUE)

pca$rotation <- -1*pca$rotation

pca$rotation

pca2 <- PCA(standard_p, scale.unit = TRUE, graph = FALSE)
summary(pca2)
plot(pca2, choix = "var")

fviz_pca_ind(pca,
             col.ind = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

fviz_pca_var(pca,
             col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

biplot(pca, main = "Biplot", scale = 0)

```

Remove correlated variables:
  - frac_snow
  - 

```{r}
filtered_cor <- cor_matrix

filtered_cor[abs(filtered_cor) < 0.8] <- NA

diag(filtered_cor) <- NA

strong_cor <- which(!is.na(filtered_cor), arr.ind = TRUE)

for (i in 1:nrow(strong_cor)) {
  row <- rownames(cor_matrix)[strong_cor[i,1]]
  col <- colnames(cor_matrix)[strong_cor[i,2]]
  correlation <- cor_matrix[strong_cor[i,1], strong_cor[i,2]]
  cat("Variable pair:", row, "-", col, ", Correlation:", correlation, "\n")
}

standard_p <- standard_p |> 
  dplyr::select(-frac_snow, -low_prec_dur, -low_prec_freq, -glim_2nd_class_frac, -max_water_content, -soil_porosity, -soil_conductivity, -soil_depth_statsgo, -lai_max, -gvf_max)
```


Make both data frames same length, define function to bind them together.
Seed value to pick 80

```{r}
standard_p_slice <- standard_p %>%
  slice_tail(n = 80)

signatures <- signatures %>%
  slice_tail(n=80)

#bind_p <- function(signature, parameters) {
 # bind_cols(signature, parameters)
#}
```

Initialize model for baseflow index (baseflow_index)

```{r}
# total number of combinations should be 80
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$baseflow_index ~ ., #BFI is what you're trying to predict 
    data            = standard_p_slice, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

#print RMSE
hyper_grid %>% 
  dplyr::arrange(OOB_RMSE)
```

# Run optimal model for baseflow index

```{r}
OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {

  optimal_ranger_bfi <- ranger(
    formula         = signatures$baseflow_index ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_bfi$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_bfi <- optimal_ranger_bfi$variable.importance %>% 
      as_tibble() %>% 
      bind_cols(names(optimal_ranger_bfi$variable.importance)) %>%
      rename(importance = value, param = '...2') %>%
      mutate(measure = "BFI")

```

# Tune and run optimal model for mean daily discharge

```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$q_mean ~ ., #BFI is what you're trying to predict 
    data            = standard_p_slice, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger_qm <- ranger(
    formula         = signatures$q_mean ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_qm$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_qm <- optimal_ranger_qm$variable.importance %>% 
  as_tibble() %>% 
  bind_cols(names(optimal_ranger_qm$variable.importance)) %>%
  rename(importance = value, param = '...2') %>%
  mutate(measure = "q_mean")

```

# Tune and run optimal model for low flow (q5)

```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$q5 ~ ., #BFI is what you're trying to predict 
    data            = standard_p_slice, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger_q5 <- ranger(
    formula         = signatures$q5 ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_q5$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_q5 <- optimal_ranger_q5$variable.importance %>% 
  as_tibble() %>% 
  bind_cols(names(optimal_ranger_q5$variable.importance)) %>%
  rename(importance = value, param = '...2') %>%
  mutate(measure = "q5")

```

# Tune and run optimal model for high flow (q95)

```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$q95 ~ ., #BFI is what you're trying to predict 
    data            = standard_p_slice, #for RF is all the other parameters
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger_q95 <- ranger(
    formula         = signatures$q95 ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 3, #was 26
    min.node.size   = 8, #was 5
    sample.fraction = .5,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_q95$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_q95 <- optimal_ranger_q95$variable.importance %>% 
  as_tibble() %>% 
  bind_cols(names(optimal_ranger_q95$variable.importance)) %>%
  rename(importance = value, param = '...2') %>%
  mutate(measure = "q95")
```

# Tune and run optimal model for Richard Baker Flashiness (RBI)

```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$RBI ~ .,  
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger_rbi <- ranger(
    formula         = signatures$RBI ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 7, #was 26
    min.node.size   = 7, #was 5
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_rbi$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_rbi <- optimal_ranger_rbi$variable.importance %>% 
  as_tibble() %>% 
  bind_cols(names(optimal_ranger_rbi$variable.importance)) %>%
  rename(importance = value, param = '...2') %>%
  mutate(measure = "RBI")
```

# Tune and run model for runoff ratio

```{r}
hyper_grid <- expand.grid(
  mtry       = seq(3,7, by = 1),
  node_size  = seq(2,9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = signatures$runoff_ratio ~ .,  
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

OOB_RMSE <- vector(mode = "numeric", length = 100)

for(i in seq_along(OOB_RMSE)) {
  
  optimal_ranger_rr <- ranger(
    formula         = signatures$runoff_ratio ~ ., 
    data            = standard_p_slice, 
    num.trees       = 500,
    mtry            = 7, 
    min.node.size   = 7, 
    sample.fraction = .8,
    importance      = 'impurity'
  )
  
  OOB_RMSE[i] <- sqrt(optimal_ranger_rr$prediction.error)
}

hist(OOB_RMSE, breaks = 20)

#All importances will be added to this table:
importancesAll_rr <- optimal_ranger_rr$variable.importance %>% 
  as_tibble() %>% 
  bind_cols(names(optimal_ranger_rr$variable.importance)) %>%
  rename(importance = value, param = '...2') %>%
  mutate(measure = "runoff_ratio")
```

# Bind all importance outputs together

```{r, fig.width=12, fig.height=6}
importancesAll <- importancesAll_bfi |> 
  rbind(importancesAll_q5) |> 
  rbind(importancesAll_q95) |> 
  rbind(importancesAll_qm) |> 
  rbind(importancesAll_rbi) |> 
  rbind(importancesAll_rr)

num_classes <- 10
colors <- viridis_pal(option = "C")(num_classes)

plot_top_n_importance <- function(data, n = 10) {
  data %>%
    group_by(measure) %>%
    top_n(n, importance) %>%
    ungroup() %>%
    #arrange(desc(importance)) %>%
    ggplot(aes(x = reorder(param, importance), y = importance, fill = param)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    facet_wrap(~ measure, scales = "free", nrow = 2) +
    labs(x = " ", y = " ") +
    scale_fill_viridis_d() +
    theme_bw() +
    theme(legend.position = "none")
}

bfi <- plot_top_n_importance(importancesAll_bfi, n = 10)
qmean <- plot_top_n_importance(importancesAll_qm, n = 10)
q5 <- plot_top_n_importance(importancesAll_q5, n = 10)
q95 <- plot_top_n_importance(importancesAll_q95, n = 10)
rr <- plot_top_n_importance(importancesAll_rr, n = 10)
rbi <- plot_top_n_importance(importancesAll_rbi, n = 10)

qmean + q5 + q95 + bfi + rr + rbi
```

# Optimal model versus observed plots

```{r, fig.width=12, fig.height=6}
standard_p80 <- slice_tail(standard_p, n = 80)

bfi_pred <- predict(optimal_ranger_bfi, data = standard_p80)$prediction
qm_pred <- predict(optimal_ranger_qm, data = standard_p80)$prediction
q95_pred <- predict(optimal_ranger_q95, data = standard_p80)$prediction
q5_pred <- predict(optimal_ranger_q5, data = standard_p80)$prediction
rr_pred <- predict(optimal_ranger_rr, data = standard_p80)$prediction
rbi_pred <- predict(optimal_ranger_rbi, data = standard_p80)$prediction

pred_list <- list(bfi_pred, qm_pred, q5_pred, q95_pred, rr_pred, rbi_pred)                   
                    
col_names <- c("BFI", "q_mean", "q95", "q5", "rr", "rbi")

signature_pred <- data.frame(setNames(pred_list, col_names)) 

plot_observed_vs_predicted <- function(signature, predicted, actual) {
  ggplot(data.frame(Actual = actual, Predicted = predicted), aes(x = Actual, y = Predicted)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, linetype = "solid", color = "blue") +  # Add 45-degree line
    labs(x = "Actual", y = "Predicted", title = paste(signature)) +
    theme_bw()
}

bfi_po <- plot_observed_vs_predicted("BFI", signature_pred$BFI, signatures$baseflow_index)
qm_po <- plot_observed_vs_predicted("Q Mean", signature_pred$q_mean, signatures$q_mean)
q95_po <- plot_observed_vs_predicted("Q95", signature_pred$q95, signatures$q95)
q5_po <- plot_observed_vs_predicted("Q5", signature_pred$q5, signatures$q5)
rr_po <- plot_observed_vs_predicted("Runoff Ratio", signature_pred$rr, signatures$runoff_ratio)
rbi_po <- plot_observed_vs_predicted("RBI", signature_pred$rbi, signatures$RBI)

qm_po + q5_po + q95_po + bfi_po + rr_po + rbi_po
```

```{r, fig.width=12, fig.height=6}
library(ggsci)
param_key <- read_csv("Data/param_key.csv")

importance_key <- merge(importancesAll, param_key, by.x = "param", by.y = "var")

importance_plot <- importance_key |> 
  ggplot(aes(x = measure, y = importance, fill = group)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  scale_color_igv() +
  scale_fill_igv() +
  #scale_fill_brewer(palette = "Dark2") +
  labs(x = "Hydrologic Measure",
       y = "Importance from RF") +
  coord_flip() +
  scale_x_discrete(labels = c("Runoff Ratio", "RBI", "High Flow (Q95)", "Low Flow (Q5)", "Mean Daily Discharge", "Baseflow Index")) +
  guides(fill = guide_legend(title = "Parameter Group"))

importance_plot
```


  
